{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [
     2,
     19,
     23,
     25,
     29,
     46,
     59,
     86,
     104,
     109,
     113,
     121,
     230,
     244,
     283,
     289
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded functions\n"
     ]
    }
   ],
   "source": [
    "#functions\n",
    "\n",
    "def loadsettings():\n",
    "    global settings\n",
    "    global pixelsPerMetric\n",
    "    global mincanny\n",
    "    global maxcanny\n",
    "    global safetyzonex\n",
    "    global safetyzoney\n",
    "    global blur\n",
    "    settings = np.asarray(pd.read_excel('settings.xlsx'))\n",
    "    pixelsPerMetric=float(settings[0,1])\n",
    "    mincanny=int(settings[1,1])\n",
    "    maxcanny=int(settings[2,1])\n",
    "    safetyzonex=int(settings[3,1])\n",
    "    safetyzoney=int(settings[4,1])\n",
    "    blur=int(settings[5,1])\n",
    "    return()\n",
    "\n",
    "def savesettings(settings):\n",
    "    settings = pd.DataFrame (settings)\n",
    "    settings.to_excel('settings.xlsx', index=False)\n",
    "    \n",
    "def nothing(x):\n",
    "    pass\n",
    "def midpoint(ptA, ptB):\n",
    "\treturn ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n",
    "\n",
    "\n",
    "def gettrackbars():\n",
    "    \n",
    "    global mincanny\n",
    "    global maxcanny\n",
    "    global safetyzonex\n",
    "    global safetyzoney\n",
    "    global blur\n",
    "    mincanny=cv2.getTrackbarPos(\"min\",\"contour\")\n",
    "    maxcanny=cv2.getTrackbarPos(\"max\",\"contour\")\n",
    "    safetyzonex=cv2.getTrackbarPos(\"borderx\",\"contour\")\n",
    "    safetyzoney=cv2.getTrackbarPos(\"bordery\",\"contour\")\n",
    "    blur=cv2.getTrackbarPos(\"Blur\",\"contour\")\n",
    "    count = blur % 2 \n",
    "    if (count == 0):\n",
    "        blur += 1\n",
    "    cv2.setTrackbarPos(\"Blur\",\"contour\",blur)\n",
    "\n",
    "def createwindow():\n",
    "    cv2.namedWindow('contour')\n",
    "    cv2.createTrackbar(\"min\",\"contour\",0,400,nothing)\n",
    "    cv2.createTrackbar(\"max\",\"contour\",0,400,nothing)\n",
    "    cv2.createTrackbar(\"borderx\",\"contour\",0,200,nothing)\n",
    "    cv2.createTrackbar(\"bordery\",\"contour\",0,200,nothing)\n",
    "    cv2.createTrackbar(\"Blur\", \"contour\", 1, 21, nothing)\n",
    "    cv2.setTrackbarPos(\"min\",\"contour\",maxcanny)\n",
    "    cv2.setTrackbarPos(\"max\",\"contour\",mincanny)\n",
    "    cv2.setTrackbarPos(\"borderx\",\"contour\",safetyzonex)\n",
    "    cv2.setTrackbarPos(\"bordery\",\"contour\",safetyzoney)\n",
    "    cv2.setTrackbarPos(\"Blur\",\"contour\",blur)\n",
    "    \n",
    "def crop_coord(img,cnt):\n",
    "    # find the exact rectangle enclosing the text area\n",
    "    # rect is a tuple consisting of 3 elements: the first element is the center\n",
    "    # of the rectangle, the second element is the width, height, and the\n",
    "    # third element is the detected rotation angle.\n",
    "    # Example output: ((227.5, 187.50003051757812),\n",
    "    # (94.57575225830078, 417.98736572265625), -36.982906341552734)\n",
    "    rect = cv2.minAreaRect(cnt)\n",
    "#    print(\"rect: {}\".format(rect))\n",
    "\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "\n",
    "    # print(\"bounding box: {}\".format(box))\n",
    "#    cv2.drawContours(img, [box], 0, (0, 0, 255), 2)\n",
    "\n",
    "    # img_crop will the cropped rectangle, img_rot is the rotated image\n",
    "    img_crop, img_rot = crop_rect(img, rect)\n",
    "    (h, w) = img_crop.shape[:2]\n",
    "    #make sure all pictures are vertical\n",
    "    if(h<w):\n",
    "        img_crop = cv2.rotate(img_crop, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "  #  cv2.waitKey(0)\n",
    "    return img_crop\n",
    "\n",
    "\n",
    "def crop_rect(img, rect):\n",
    "    # get the parameter of the small rectangle\n",
    "    center, size, angle = rect[0], rect[1], rect[2]\n",
    "    center, size = tuple(map(int, center)), tuple(map(int, size))\n",
    "\n",
    "    # get row and col num in img\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "\n",
    "    # calculate the rotation matrix\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "    # rotate the original image\n",
    "    img_rot = cv2.warpAffine(img, M, (width, height))\n",
    "\n",
    "    # now rotated rectangle becomes vertical and we crop it\n",
    "    img_crop = cv2.getRectSubPix(img_rot, size, center)\n",
    "\n",
    "    return img_crop, img_rot\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "#-----------------------------calculate shapes and dimensions-----------\n",
    "\n",
    "\n",
    "def midpoint(ptA, ptB):\n",
    "\treturn ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n",
    "\n",
    "#------check if the prediction goes over a given percentage\n",
    "def checkprediction(prediction,percentage):\n",
    "    #print(max(prediction))\n",
    "    if(max(prediction)>=percentage):\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)\n",
    "\n",
    "#-----check if siluett is inside other (works only for rectangles)\n",
    "def isinside(coord1,coord2):\n",
    "    \n",
    "    coord1=np.array(coord1)\n",
    "    coord2=np.array(coord2)\n",
    "\n",
    "    m1=(coord1[1,1]-coord1[0,1])/(coord1[1,0]-coord1[0,0])\n",
    "    b1=coord1[0,1]/(m1*coord1[0,0])\n",
    "    \n",
    "    m2=(coord1[3,1]-coord1[0,1])/(coord1[3,0]-coord1[0,0])\n",
    "    b2=coord1[0,1]/(m2*coord1[0,0])\n",
    "\n",
    "    answere=False\n",
    "    \n",
    "    for x in range(4):\n",
    "        testx=coord2[x,0]\n",
    "        testy=coord2[x,1]\n",
    "\n",
    "        if((m1*coord1[0,0]+b1<=m1*testx+b1 and m1*testx+b1<=m1*coord1[1,0]+b1) or (m1*coord1[0,0]+b1>=m1*testx+b1 and m1*testx+b1>=m1*coord1[1,0]+b1)):\n",
    "            if(((coord1[0,1]-b2)/m2<=(testy-b2)/m1 and (testy-b2)/m2 <= (coord1[3,1]-b2)/m2) or ((coord1[0,1]-b2)/m2>=(testy-b2)/m2 and (testy-b2)/m2 >= (coord1[3,1]-b2)/m2)):\n",
    "                answere=True\n",
    "                \n",
    "    return(answere)\n",
    "\n",
    "\n",
    "#------------extract data from table screw\n",
    "def extractscrew(table,short,long):\n",
    "    ammdia=int(table[0][0])\n",
    "    ammlen=int(table[0][1])\n",
    "    \n",
    "    ztemp=0\n",
    "    real=True\n",
    "\n",
    "    for z in range(1,ammdia):\n",
    "        screwname = \"Null\"\n",
    "        if (short >= table[z][1] and short < table[z+1][1]):\n",
    "           # print(\"ENTERED\")\n",
    "            #nutname = \"between\" + str(table[z][0]) +\"and\" +str(table[z][0])\n",
    "            delta_1 = abs(short - float(table[z][1]))\n",
    "            #print(delta_1)\n",
    "            delta_2 = abs(short - float(table[z+1][1]))\n",
    "            #print(delta_2)\n",
    "            if delta_1 <= delta_2:\n",
    "                screwname = str(table[z][0])\n",
    "                ztemp=z\n",
    "            if delta_1 > delta_2:\n",
    "                screwname = str(table[z+1][0])\n",
    "                ztemp=z\n",
    "            #if delta_1 == delta_2:\n",
    "                #nutname = \"can't decide between\" + str(table[z][0]) +\"and\" +str(table[z][0])\n",
    "            break\n",
    "        else:\n",
    "            #Too small\n",
    "            if(short < table[1,1]-0.5*table[1,1]):\n",
    "                screwname = \"Too small to be a Screw\"\n",
    "                real=False\n",
    "            #between too small and first value\n",
    "            if (short > table[1,1]-0.5*table[1,1] and short <= table[1,1]):\n",
    "                screwname = str(table[1][0])\n",
    "                ztemp=z\n",
    "            #too big    \n",
    "            if(short > table[ammdia,1]+1.5):\n",
    "                screwname = \"Not in range\"\n",
    "                real=False\n",
    "            #between too big and last value\n",
    "            if (short > table[ammdia,1]-1.5 and short <= table[ammdia,1]+1.5):\n",
    "                screwname = str(table[ammdia][0])\n",
    "                ztemp=ammdia\n",
    "                \n",
    "  #  ztemp+=1            \n",
    "   # print(ztemp)\n",
    "    \n",
    "    for z in range(3,ammlen+2):\n",
    "        screwlen = \"Null\"\n",
    "        if (long >= table[ztemp,z] and long < table[ztemp][z+1]):\n",
    "            #print(\"ENTERED\")\n",
    "            #nutname = \"between\" + str(table[z][0]) +\"and\" +str(table[z][0])\n",
    "            delta_1 = abs(long - float(table[ztemp][z]))\n",
    "            #print(delta_1)\n",
    "            delta_2 = abs(long - float(table[ztemp][z+1]))\n",
    "            #print(delta_2)\n",
    "            if delta_1 <= delta_2:\n",
    "                screwlen = str(table[0][z])\n",
    "            if delta_1 > delta_2:\n",
    "                screwlen = str(table[0][z+1])\n",
    "            #if delta_1 == delta_2:\n",
    "                #nutname = \"can't decide between\" + str(table[z][0]) +\"and\" +str(table[z][0])\n",
    "            break\n",
    "        else:\n",
    "            #Too small\n",
    "            if (long < table[ztemp,3]*0.5):\n",
    "                screwlen = \"Too short to be a Screw\"\n",
    "                real=False\n",
    "            #between too small and first value\n",
    "            if (long > table[ztemp,3]*0.5 and long <= table[ztemp,3]):\n",
    "                screwlen = str(table[0][3])\n",
    "            #too big    \n",
    "            if (long > table[ztemp,ammlen+2]+1.5):\n",
    "                screwlen = \"Not in range\"\n",
    "                real=False\n",
    "            #between too big and last value\n",
    "            if (long > table[ztemp,ammlen+2]-1.5 and long <= table[ztemp,ammlen+2]+1.5):\n",
    "                screwlen = str(table[0,ammlen+2])          \n",
    "   \n",
    "    screwname=screwname+\"X\"+screwlen\n",
    "    if real==False:\n",
    "        screwname=\"n.a.\"\n",
    "    return(screwname)\n",
    "\n",
    "#-----extract data from table nut\n",
    "def extractnut(table,short, long):\n",
    "    \n",
    "    SW=np.asarray(table['SW'].tolist())\n",
    "    e=np.asarray(table['e'].tolist())\n",
    "    name=table['Name'].tolist()\n",
    "    absolute_val_SW = np.abs(SW - short)\n",
    "    absolute_val_e = np.abs(e - long)\n",
    "    absolute_val_comb=np.add(absolute_val_SW,absolute_val_e)\n",
    "    smallest_difference_index = absolute_val_comb.argmin()\n",
    "    closest_element = name[smallest_difference_index]\n",
    "    check=absolute_val_comb[smallest_difference_index]\n",
    "    return(closest_element)\n",
    "\n",
    "#-----extract data from table washer\n",
    "def extractwasher(table,diaout,diain):\n",
    "    d1=np.asarray(table['d1'].tolist())\n",
    "    d2=np.asarray(table['d2'].tolist())\n",
    "    name=unterlegscheibe['Size'].tolist()\n",
    "    absolute_val_d1 = np.abs(d1 - diain)\n",
    "    absolute_val_d2 = np.abs(d2 - diaout)\n",
    "    absolute_val_comb=np.add(absolute_val_d1,absolute_val_d2)\n",
    "    smallest_difference_index = absolute_val_comb.argmin()\n",
    "    closest_element = name[smallest_difference_index]\n",
    "    check=absolute_val_comb[smallest_difference_index]\n",
    "    \n",
    "    return(closest_element)\n",
    "\n",
    "#---------Function for comparing measurments to table\n",
    "def compare(name,x,y):\n",
    "    if(x>y):\n",
    "        short=y\n",
    "        long=x\n",
    "    if(x<=y):\n",
    "        short=x\n",
    "        long=y\n",
    "    \n",
    "    if(name==\"zylinderschr.\"):\n",
    "        name=extractscrew(zylinderschraube,short,long)\n",
    "        \n",
    "    if(name==\"sechskantschr.\"):\n",
    "        name=extractscrew(sechskantschraube,short,long)\n",
    "\n",
    "    if(name==\"mutter\"):\n",
    "        name=extractnut(mutter,short,long)\n",
    "            \n",
    "    if(name==\"unterlegscheibe\"):\n",
    "        name=extractwasher(unterlegscheibe,long,short)  \n",
    "        \n",
    "    if(name==\"senkkopfschr.\"):\n",
    "        name=extractscrew(senkschraube,long,short)   \n",
    "        \n",
    "    return(name)\n",
    "\n",
    "def change_res(width, height):\n",
    "    \n",
    "    global videoCaptureObject\n",
    "    videoCaptureObject.set(3, width)\n",
    "    videoCaptureObject.set(4, height)\n",
    "    \n",
    "def checkboundry(coord,h,w):\n",
    "    if(coord[0,0]<=safetyzonex):\n",
    "        return(False)\n",
    "    if(coord[0,1]<=safetyzoney):\n",
    "        return(False)\n",
    "    if(coord[1,0]>=w-safetyzonex):\n",
    "        return(False)\n",
    "    if(coord[1,1]<=safetyzoney):\n",
    "        return(False)\n",
    "    if(coord[2,0]>=w-safetyzonex):\n",
    "        return(False)\n",
    "    if(coord[2,1]>=h-safetyzoney):\n",
    "        return(False)\n",
    "    if(coord[3,0]<=safetyzonex):\n",
    "        return(False)\n",
    "    if(coord[3,1]>=h-safetyzoney):\n",
    "        return(False)\n",
    "    return(True)\n",
    "\n",
    "def getscrewhead(screwimg):\n",
    "    \n",
    "    img = Image.fromarray(screwimg)\n",
    "    \n",
    "    \n",
    "  \n",
    "    # Size of the image in pixels (size of orginal image) \n",
    "    # (This is not mandatory) \n",
    "    width, height = img.size \n",
    "\n",
    "\n",
    "    # Cropped image of above dimension \n",
    "    # (It will not change orginal image) \n",
    "    image1 = np.array(img.crop((0, 0, width, width*0.6)))\n",
    "    image2 = np.array(img.crop((0, height-(width*0.6), width, height)))\n",
    "    \n",
    "    return(image1,image2)\n",
    "\n",
    "print(\"Loaded functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imutils import perspective\n",
    "from imutils import contours\n",
    "from scipy.spatial import distance as dist\n",
    "import argparse\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(\"Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diameter of object? 49.6\n",
      "Settings saved. Calibration done!\n"
     ]
    }
   ],
   "source": [
    "#calibration\n",
    "loadsettings()\n",
    "\n",
    "videoCaptureObject = cv2.VideoCapture(1)\n",
    "\n",
    "change_res(1920, 1080)\n",
    "\n",
    "width=float(input(\"Diameter of object? \"))\n",
    "\n",
    "\n",
    "createwindow()\n",
    "\n",
    "while(True):\n",
    "    ret,frame = videoCaptureObject.read()\n",
    "    image = frame\n",
    "    imagefinal = image\n",
    "    orig = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    gettrackbars()\n",
    "\n",
    "    gray = cv2.GaussianBlur(gray, (blur, blur), 0)\n",
    "    \n",
    "\n",
    "    edged = cv2.Canny(gray, mincanny, maxcanny)\n",
    "    edged = cv2.dilate(edged, None, iterations=1)\n",
    "    edged = cv2.erode(edged, None, iterations=1)\n",
    "\n",
    "\n",
    "    # find contours in the edge map\n",
    "    cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    if(len(cnts)>=1):\n",
    "\n",
    "        # sort the contours from left-to-right and initialize the\n",
    "        # 'pixels per metric' calibration variable\n",
    "        (cnts, _) = contours.sort_contours(cnts)\n",
    "                            \n",
    "\n",
    "        # loop over the contours individually\n",
    "        for c in cnts:\n",
    "\n",
    "            # if the contour is not sufficiently large, ignore it\n",
    "            if cv2.contourArea(c) < 100:\n",
    "                continue\n",
    "\n",
    "            # compute the rotated bounding box of the contour\n",
    "\n",
    "            box = cv2.minAreaRect(c)\n",
    "            box = cv2.cv.BoxPoints(box) if imutils.is_cv2() else cv2.boxPoints(box)\n",
    "            box = np.array(box, dtype=\"int\")\n",
    "            box = perspective.order_points(box)\n",
    "\n",
    "            #check that object is fully in the image\n",
    "\n",
    "            coord=np.asarray(box)\n",
    "            (h, w) = orig.shape[:2]\n",
    "            if(coord[0,0]<=safetyzonex):\n",
    "                continue\n",
    "            if(coord[0,1]<=safetyzoney):\n",
    "                continue\n",
    "            if(coord[1,0]>=w-safetyzonex):\n",
    "                continue\n",
    "            if(coord[1,1]<=safetyzoney):\n",
    "                continue\n",
    "            if(coord[2,0]>=w-safetyzonex):\n",
    "                continue\n",
    "            if(coord[2,1]>=h-safetyzoney):\n",
    "                continue\n",
    "            if(coord[3,0]<=safetyzonex):\n",
    "                continue\n",
    "            if(coord[3,1]>=h-safetyzoney):\n",
    "                continue\n",
    "\n",
    "            cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n",
    "            # loop over the original points and draw them\n",
    "            for (x, y) in box:\n",
    "                cv2.circle(orig, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "            (tl, tr, br, bl) = box\n",
    "            (tltrX, tltrY) = midpoint(tl, tr)\n",
    "            (blbrX, blbrY) = midpoint(bl, br)\n",
    "            (tlblX, tlblY) = midpoint(tl, bl)\n",
    "            (trbrX, trbrY) = midpoint(tr, br)\n",
    "            dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n",
    "            dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n",
    "\n",
    "\n",
    "            pixelsPerMetric = dB /width\n",
    "            dimA = dA / pixelsPerMetric\n",
    "            dimB = dB / pixelsPerMetric\n",
    "            \n",
    "\n",
    "            cv2.putText(orig, \"{:.1f}mm\".format(dimA),\n",
    "                (int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.65, (0, 0, 0), 2)\n",
    "            cv2.putText(orig, \"{:.1f}mm\".format(dimB),\n",
    "                (int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.65, (0, 0, 0), 2)\n",
    "\n",
    "    (h, w) = orig.shape[:2]\n",
    "    cv2.rectangle(orig, (safetyzonex,safetyzoney), (w-safetyzonex,h-safetyzoney), (0, 0, 255) , 2)\n",
    "\n",
    "    cv2.imshow('Capturing Video',orig)\n",
    "    cv2.imshow('contour',edged)                        \n",
    "\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        videoCaptureObject.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "settings[0,1]=pixelsPerMetric\n",
    "settings[1,1]=mincanny\n",
    "settings[2,1]=maxcanny \n",
    "settings[3,1]=safetyzonex\n",
    "settings[4,1]=safetyzoney\n",
    "settings[5,1]=blur\n",
    "savesettings(settings)\n",
    "\n",
    "print(\"Settings saved. Calibration done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Harvesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n",
      "Number of frames: 1000\n",
      "Name the object or type exit: zylinderkopf\n",
      "Name the object or type exit: exit\n",
      "exit\n"
     ]
    }
   ],
   "source": [
    "#Get images for Machine Learning\n",
    "\n",
    "\n",
    "print(\"import done\")\n",
    "width=35\n",
    "record=True\n",
    "screw=True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "videoCaptureObject = cv2.VideoCapture(1)\n",
    "change_res(1920, 1080)\n",
    "frames=input(\"Number of frames: \")\n",
    "\n",
    "active=True\n",
    "\n",
    "\n",
    "loadsettings()\n",
    "while(active==True):\n",
    "    i=0\n",
    "    eingabe=input(\"Name the object or type exit: \")\n",
    "    createwindow()\n",
    "    if(eingabe==\"exit\"):\n",
    "        videoCaptureObject.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    path = 'C:/Users/maxim/Documents/Python/data/Train/'+eingabe\n",
    "    if(os.path.exists(path)==False):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    while(i<int(frames) and active==True):    \n",
    "        ret,frame = videoCaptureObject.read()\n",
    "\n",
    "        image = frame\n",
    "        imagefinal = image\n",
    "        orig = image.copy()\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        gettrackbars()    \n",
    "        gray = cv2.GaussianBlur(gray, (blur, blur), 0)\n",
    "        #gray = cv2.bilateralFilter(gray, 30, 80, 80)\n",
    "        # perform edge detection, then perform a dilation + erosion to\n",
    "        # close gaps in between object edges\n",
    "\n",
    "        edged = cv2.Canny(gray, mincanny, maxcanny)\n",
    "        edged = cv2.dilate(edged, None, iterations=1)\n",
    "        edged = cv2.erode(edged, None, iterations=1)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        # find contours in the edge map\n",
    "        cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        if(len(cnts)>=1):\n",
    "\n",
    "            # sort the contours from left-to-right and initialize the\n",
    "            # 'pixels per metric' calibration variable\n",
    "            (cnts, _) = contours.sort_contours(cnts)\n",
    "            if(pixelsPerMetric==0):\n",
    "                pixelsPerMetric = None\n",
    "\n",
    "            \n",
    "            # loop over the contours individually\n",
    "            for c in cnts:\n",
    "                \n",
    "                # if the contour is not sufficiently large, ignore it\n",
    "                if cv2.contourArea(c) < 300:\n",
    "                    continue\n",
    "                \n",
    "\n",
    "                    \n",
    "                    \n",
    "                # compute the rotated bounding box of the contour\n",
    "                \n",
    "                box = cv2.minAreaRect(c)\n",
    "                box = cv2.cv.BoxPoints(box) if imutils.is_cv2() else cv2.boxPoints(box)\n",
    "                box = np.array(box, dtype=\"int\")\n",
    "                # order the points in the contour such that they appear\n",
    "                # in top-left, top-right, bottom-right, and bottom-left\n",
    "                # order, then draw the outline of the rotated bounding\n",
    "                # box\n",
    "                box = perspective.order_points(box)\n",
    "                \n",
    "                #check that object is fully in the image\n",
    "                \n",
    "                coord=np.asarray(box)\n",
    "                (h, w) = orig.shape[:2]\n",
    "                \n",
    "                if checkboundry(coord,h,w)==False:\n",
    "                    continue\n",
    "\n",
    "                cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n",
    "                \n",
    "                # loop over the original points and draw them\n",
    "                for (x, y) in box:\n",
    "                    cv2.circle(orig, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "\n",
    "\n",
    "                # unpack the ordered bounding box, then compute the midpoint\n",
    "                # between the top-left and top-right coordinates, followed by\n",
    "                # the midpoint between bottom-left and bottom-right coordinates\n",
    "                (tl, tr, br, bl) = box\n",
    "                (tltrX, tltrY) = midpoint(tl, tr)\n",
    "                (blbrX, blbrY) = midpoint(bl, br)\n",
    "                # compute the midpoint between the top-left and top-right points,\n",
    "                # followed by the midpoint between the top-righ and bottom-right\n",
    "                (tlblX, tlblY) = midpoint(tl, bl)\n",
    "                (trbrX, trbrY) = midpoint(tr, br)\n",
    "                # draw the midpoints on the image\n",
    "\n",
    "                # compute the Euclidean distance between the midpoints\n",
    "                dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n",
    "                dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n",
    "                # if the pixels per metric has not been initialized, then\n",
    "                # compute it as the ratio of pixels to supplied metric\n",
    "                # (in this case, inches)age\n",
    "                if pixelsPerMetric is None:\n",
    "                    pixelsPerMetric = dB / width\n",
    "                    #print(pixelsPerMetric)\n",
    "\n",
    "                # compute the size of the object\n",
    "                dimA = dA / pixelsPerMetric\n",
    "                dimB = dB / pixelsPerMetric\n",
    "                # draw the object sizes on the image\n",
    "                cv2.putText(orig, \"{:.1f}mm\".format(dimA),\n",
    "                    (int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.65, (255, 255, 255), 2)\n",
    "                cv2.putText(orig, \"{:.1f}mm\".format(dimB),\n",
    "                    (int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.65, (255, 255, 255), 2)\n",
    "\n",
    "                coord[0,0]=coord[0,0]-10\n",
    "                coord[0,1]=coord[0,1]-10\n",
    "                coord[1,0]=coord[1,0]+10\n",
    "                coord[1,1]=coord[1,1]-10\n",
    "                coord[2,0]=coord[2,0]+10\n",
    "                coord[2,1]=coord[2,1]+10\n",
    "                coord[3,0]=coord[3,0]-10\n",
    "                coord[3,1]=coord[3,1]+10\n",
    "                image = crop_coord(imagefinal,coord)\n",
    "                if record==True:\n",
    "                    \n",
    "                    if screw==True:\n",
    "                        img1,img2=getscrewhead(image)\n",
    "                        cv2.imwrite(\"C:/Users/maxim/Documents/Python/data/Train/\"+eingabe+\"/cropped_img-\"+str(i)+\".jpg\", img1)\n",
    "                        cv2.imwrite(\"C:/Users/maxim/Documents/Python/data/Train/\"+eingabe+\"/cropped_img-\"+str(i)+\"_.jpg\", img2)\n",
    "                        i=i+1\n",
    "                    else:\n",
    "                        cv2.imwrite(\"C:/Users/maxim/Documents/Python/data/Train/\"+eingabe+\"/cropped_img-\"+str(i)+\".jpg\", image)\n",
    "                        i=i+1\n",
    "        (h, w) = orig.shape[:2]\n",
    "        cv2.rectangle(orig, (safetyzonex,safetyzoney), (w-safetyzonex,h-safetyzoney), (0, 0, 255) , 2)\n",
    "        cv2.imshow('contour',edged)                        \n",
    "        cv2.imshow('Capturing Video',orig)\n",
    "#        cv2.imwrite(os.path.join(path,imgname),crop_img)\n",
    "        if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "            videoCaptureObject.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            active=False\n",
    "    \n",
    "print(\"exit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking training images and crating dataset (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#TAKES FILES IN FOLDERS AND GIVE OUT X(IMAGES) AND Y(LABEL)\n",
    "\n",
    "file_list = []\n",
    "class_list = []\n",
    "\n",
    "DATADIR = \"data/Train\"\n",
    "\n",
    "\n",
    "# All the categories you want your neural network to detect\n",
    "CATEGORIES = [\"mutter\",\"unterlegscheibe\",\"schraube\"]\n",
    "\n",
    "# The size of the images that your neural network will use\n",
    "IMG_SIZE = 256\n",
    "# Checking or all images in the data folder\n",
    "for category in CATEGORIES :\n",
    "\tpath = os.path.join(DATADIR, category)\n",
    "\tfor img in os.listdir(path):\n",
    "#\t\timg_array = cv2.imread(os.path.join(path, img))\n",
    "\t\timg_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "training_data = []\n",
    "def create_training_data():\n",
    "\tfor category in CATEGORIES :\n",
    "\t\tpath = os.path.join(DATADIR, category)\n",
    "\t\tclass_num = CATEGORIES.index(category)\n",
    "\t\tfor img in os.listdir(path):\n",
    "\t\t\ttry :\n",
    "\t\t\t\timg_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "\t\t\t\tnew_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "\t\t\t\ttraining_data.append([new_array, class_num])\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tpass\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "#print(training_data)\n",
    "\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = [] #features\n",
    "y = [] #labels\n",
    "\n",
    "for features, label in training_data:\n",
    "\tX.append(features)\n",
    "\ty.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "# Creating the files containing all the information about your model\n",
    "pickle_out = open(\"Xtrain.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"ytrain.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_in = open(\"Xtrain.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "#FILES SAVED\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking training images and crating dataset (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#TAKES FILES IN FOLDERS AND GIVE OUT Xtest(IMAGES) AND Ytest(LABEL)\n",
    "\n",
    "file_list = []\n",
    "class_list = []\n",
    "\n",
    "DATADIR = \"data/Test\"\n",
    "\n",
    "# All the categories you want your neural network to detect\n",
    "CATEGORIES = [\"mutter\",\"unterlegscheibe\",\"schraube\"]\n",
    "\n",
    "# The size of the images that your neural network will use\n",
    "IMG_SIZE = 256\n",
    "# Checking or all images in the data folder\n",
    "for category in CATEGORIES :\n",
    "\tpath = os.path.join(DATADIR, category)\n",
    "\tfor img in os.listdir(path):\n",
    "#\t\timg_array = cv2.imread(os.path.join(path, img))\n",
    "\t\timg_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "training_data = []\n",
    "def create_training_data():\n",
    "\tfor category in CATEGORIES :\n",
    "\t\tpath = os.path.join(DATADIR, category)\n",
    "\t\tclass_num = CATEGORIES.index(category)\n",
    "\t\tfor img in os.listdir(path):\n",
    "\t\t\ttry :\n",
    "\t\t\t\timg_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "\t\t\t\tnew_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "\t\t\t\ttraining_data.append([new_array, class_num])\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tpass\n",
    "\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "#print(training_data)\n",
    "\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = [] #features\n",
    "y = [] #labels\n",
    "\n",
    "for features, label in training_data:\n",
    "\tX.append(features)\n",
    "\ty.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "# Creating the files containing all the information about your model\n",
    "pickle_out = open(\"Xtest.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"ytest.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_in = open(\"Xtest.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "#FILES SAVED\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feeding the data into the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 254, 254, 16)      160       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 254, 254, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 127, 127, 16)      0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 258064)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                8258080   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 99        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 8,258,339\n",
      "Trainable params: 8,258,339\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 2.1286 - accuracy: 0.3242 - val_loss: 1.0985 - val_accuracy: 0.3360\n",
      "Epoch 2/2\n",
      "65/65 [==============================] - 44s 669ms/step - loss: 1.0983 - accuracy: 0.3434 - val_loss: 1.0980 - val_accuracy: 0.3360\n",
      "Saved model to disk\n",
      "WARNING:tensorflow:From c:\\users\\maxim\\.conda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: innolabscrews.model\\assets\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x170347ad348>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training NN\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "\n",
    "\n",
    "# Opening the files about data\n",
    "Xtrain = pickle.load(open(\"Xtrain.pickle\", \"rb\"))\n",
    "ytrain = pickle.load(open(\"ytrain.pickle\", \"rb\"))\n",
    "\n",
    "testX = pickle.load(open(\"Xtest.pickle\", \"rb\"))\n",
    "testY = pickle.load(open(\"ytest.pickle\", \"rb\"))\n",
    "\n",
    "# normalizing data (a pixel goes from 0 to 255)\n",
    "Xtrain = Xtrain/255.0\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "#------------THIS IS THE NEURAL NETWORK\n",
    "# Building the model\n",
    "model = Sequential()\n",
    "# 3 convolutional layers\n",
    "model.add(Conv2D(16, (3, 3), input_shape = Xtrain.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "# 2 hidden layers\n",
    "model.add(Flatten(input_shape = Xtrain.shape[1:]))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "#model.add(Dense(64))\n",
    "#model.add(Activation(\"relu\"))\n",
    "\n",
    "\n",
    "# The output layer with 3 neurons, for 13 classes\n",
    "model.add(Dense(3))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "# Compiling the model using some basic parameters\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "\t\t\t\toptimizer=\"adam\",\n",
    "\t\t\t\tmetrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "xar=np.array(Xtrain)\n",
    "yar=np.array(ytrain)\n",
    "\n",
    "testX=np.array(testX)\n",
    "testY=np.array(testY)\n",
    "\n",
    "\n",
    "#---------TRAINING DATA GENERATOR (AUGMENTATION)\n",
    "\n",
    "#train_datagen = ImageDataGenerator(brightness_range=[0.8,1.2],vertical_flip=True)\n",
    "train_datagen = ImageDataGenerator(vertical_flip=True)\n",
    "#print(yar)\n",
    "# Training the model, with 40 iterations\n",
    "# validation_split corresponds to the percentage of images used for the validation phase compared to all the images\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "#--------ACTUALLY TRAINING THE NETWORK\n",
    "# history = model.fit(train_datagen.flow(Xtrain, ytrain, batch_size = 32),\n",
    "#  validation_data = train_datagen.flow(testX, testY, batch_size=32), steps_per_epoch = len(Xtrain) // 32,\n",
    "# # epochs =100)\n",
    "#  epochs = 100,callbacks=[callback])\n",
    "\n",
    "history = model.fit(xar, yar, batch_size=32,  epochs=2, validation_split=0.3)\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"innolabscrews.json\", \"w\") as json_file :\n",
    "\tjson_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"innolabscrews.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "model.save('innolabscrews.model')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Printing a graph showing the accuracy changes during the training phase\n",
    "print(history.history.keys())\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML model loaded\n"
     ]
    }
   ],
   "source": [
    "#Load Model\n",
    "\n",
    "basemodel = tf.keras.models.load_model(\"base_ident.h5\", compile=False)\n",
    "screwmodel = tf.keras.models.load_model(\"screw_ident.h5\", compile=False)\n",
    "domenutmodel = tf.keras.models.load_model(\"domenut_ident.h5\", compile=False)\n",
    "\n",
    "print(\"ML model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exit\n"
     ]
    }
   ],
   "source": [
    "#live detection\n",
    "\n",
    "BASECATEGORIES = [\"unterlegscheibe\",\"mutter\",\"schraube\",\"hutmutter\"]\n",
    "SCREWCATEGORIES = [\"zylinderschr.\",\"senkkopfschr.\",\"sechskantschr.\",\"gewinde\"]\n",
    "DOMENUTCATEGORIES = [\"hutmutter_seite\",\"hutmutter_oben\"]\n",
    "#CATEGORIES = [\"washer\",\"nut\",\"zylinder\",\"hex\"]\n",
    "\n",
    "\n",
    "zylinderschraube = np.asarray(pd.read_excel('zylinderschraube.xlsx'))\n",
    "mutter = pd.read_excel('mutter.xlsx')\n",
    "sechskantschraube = np.asarray(pd.read_excel('sechskantschraube.xlsx'))\n",
    "unterlegscheibe = pd.read_excel('unterlegscheibe.xlsx')\n",
    "senkschraube = np.asarray(pd.read_excel('senkschraube.xlsx'))\n",
    "\n",
    "\n",
    "dimensions=3\n",
    "IMG_SIZE = 224\n",
    "width=35\n",
    "camera=1\n",
    "padding=10\n",
    "\n",
    "\n",
    "\n",
    "videoCaptureObject = cv2.VideoCapture(camera)\n",
    "change_res(1920, 1080)\n",
    "\n",
    "\n",
    "active=True\n",
    "\n",
    "\n",
    "\n",
    "#-----------Program loop\n",
    "\n",
    "loadsettings()\n",
    "\n",
    "createwindow()\n",
    "\n",
    "while(active==True):    \n",
    "    ret,frame = videoCaptureObject.read()\n",
    "\n",
    "    image = frame\n",
    "    imagefinal = image\n",
    "    orig = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # perform edge detection, then perform a dilation + erosion to\n",
    "    # close gaps in between object edges\n",
    "    gettrackbars()\n",
    "    gray = cv2.GaussianBlur(gray, (blur, blur), 0)\n",
    "    edged = cv2.Canny(gray, mincanny, maxcanny)\n",
    "    edged = cv2.dilate(edged, None, iterations=1)\n",
    "    edged = cv2.erode(edged, None, iterations=1)\n",
    "\n",
    "\n",
    "    # find contours in the edge map\n",
    "    cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    if(len(cnts)>=1):\n",
    "\n",
    "        # sort the contours from left-to-right and initialize the\n",
    "        # 'pixels per metric' calibration variable\n",
    "        (cnts, _) = contours.sort_contours(cnts)\n",
    "                            \n",
    "\n",
    "        # loop over the contours individually\n",
    "        for c in cnts:\n",
    "\n",
    "            # if the contour is not sufficiently large, ignore it\n",
    "            if cv2.contourArea(c) < 100:\n",
    "                continue\n",
    "\n",
    "            # compute the rotated bounding box of the contour\n",
    "\n",
    "            box = cv2.minAreaRect(c)\n",
    "            box = cv2.cv.BoxPoints(box) if imutils.is_cv2() else cv2.boxPoints(box)\n",
    "            box = np.array(box, dtype=\"int\")\n",
    "            # order the points in the contour such that they appear\n",
    "            # in top-left, top-right, bottom-right, and bottom-left\n",
    "            # order, then draw the outline of the rotated bounding\n",
    "            # box\n",
    "            box = perspective.order_points(box)\n",
    "            \n",
    "            #check that object is fully in the image\n",
    "\n",
    "            coord=np.asarray(box)\n",
    "            (h, w) = orig.shape[:2]\n",
    "            if checkboundry(coord,h,w)==False:\n",
    "                continue\n",
    "                 \n",
    "                   \n",
    "            #-------Extract padded image for ML Analysis\n",
    "            coordml=coord.copy()\n",
    "            coordml[0,0]=coordml[0,0]-padding\n",
    "            coordml[0,1]=coordml[0,1]-padding\n",
    "            coordml[1,0]=coordml[1,0]+padding\n",
    "            coordml[1,1]=coordml[1,1]-padding\n",
    "            coordml[2,0]=coordml[2,0]+padding\n",
    "            coordml[2,1]=coordml[2,1]+padding\n",
    "            coordml[3,0]=coordml[3,0]-padding\n",
    "            coordml[3,1]=coordml[3,1]+padding\n",
    "\n",
    "#            predimage = crop_coord(imagefinal,coordml)\n",
    "\n",
    "            predimage = crop_coord(image,coordml)\n",
    "            \n",
    "            washerimage=predimage.copy()\n",
    "\n",
    "            #------NN Detection--------\n",
    "            #----OLD\n",
    "            \n",
    "            \n",
    "#             predimage = cv2.resize(predimage, (IMG_SIZE, IMG_SIZE))\n",
    "#             predimage = predimage.reshape(IMG_SIZE, IMG_SIZE, dimensions)\n",
    "\n",
    "#             prediction = model.predict(np.array([predimage]))\n",
    "\n",
    "            #----NEW\n",
    "            preddata = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "            #resize the image to a 224x224 with the same strategy as in TM2:\n",
    "            #resizing the image to be at least 224x224 and then cropping from the center\n",
    "            size = (224, 224)\n",
    "            predimage = ImageOps.fit(Image.fromarray(predimage), size, Image.ANTIALIAS)\n",
    "\n",
    "            #turn the image into a numpy array\n",
    "            predimage_array = np.asarray(predimage)\n",
    "\n",
    "            # Normalize the image\n",
    "            normalized_predimage_array = (predimage_array.astype(np.float32) / 127.0) - 1\n",
    "            # Load the image into the array\n",
    "            preddata[0] = normalized_predimage_array\n",
    "            prediction = basemodel.predict(preddata)\n",
    "            prediction = list(prediction[0])\n",
    "            prediction= BASECATEGORIES[prediction.index(max(prediction))]\n",
    "            \n",
    "\n",
    "                \n",
    "            \n",
    "            #--------------Draw outlines and information on the image\n",
    "            cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n",
    "            # loop over the original points and draw them\n",
    "            for (x, y) in box:\n",
    "                cv2.circle(orig, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "\n",
    "\n",
    "            # unpack the ordered bounding box, then compute the midpoint\n",
    "            # between the top-left and top-right coordinates, followed by\n",
    "            # the midpoint between bottom-left and bottom-right coordinates\n",
    "            (tl, tr, br, bl) = box\n",
    "            (tltrX, tltrY) = midpoint(tl, tr)\n",
    "            (blbrX, blbrY) = midpoint(bl, br)\n",
    "            # compute the midpoint between the top-left and top-right points,\n",
    "            # followed by the midpoint between the top-righ and bottom-right\n",
    "            (tlblX, tlblY) = midpoint(tl, bl)\n",
    "            (trbrX, trbrY) = midpoint(tr, br)\n",
    "\n",
    "\n",
    "            # compute the Euclidean distance between the midpoints\n",
    "            dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n",
    "            dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n",
    "            # if the pixels per metric has not been initialized, then\n",
    "            # compute it as the ratio of pixels to supplied metric\n",
    "            # (in this case, inches)age\n",
    "\n",
    "            # compute the size of the object\n",
    "            dimA = dA / pixelsPerMetric\n",
    "            dimB = dB / pixelsPerMetric\n",
    "\n",
    "            # draw the object sizes on the image\n",
    "            cv2.putText(orig, \"{:.1f}mm\".format(dimA),\n",
    "                (int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.55, (0, 0, 0), 2)\n",
    "            cv2.putText(orig, \"{:.1f}mm\".format(dimB),\n",
    "                (int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.55, (0, 0, 0), 2)\n",
    "            \n",
    "            \n",
    "                        \n",
    "            #-----------Split into subgroups\n",
    "            \n",
    "            #----------Screws\n",
    "\n",
    "            if prediction==\"schraube\":\n",
    "                img1,img2=getscrewhead(washerimage)\n",
    "                \n",
    "                \n",
    "                preddata1 = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "                size = (224, 224)\n",
    "                predimage1 = ImageOps.fit(Image.fromarray(img1), size, Image.ANTIALIAS)\n",
    "\n",
    "                #turn the image into a numpy array\n",
    "                predimage1_array = np.asarray(predimage1)\n",
    "\n",
    "                # Normalize the image\n",
    "                normalized_predimage1_array = (predimage1_array.astype(np.float32) / 127.0) - 1\n",
    "                # Load the image into the array\n",
    "                preddata1[0] = normalized_predimage1_array\n",
    "                \n",
    "                \n",
    "                prediction1=screwmodel.predict(preddata1)\n",
    "                prediction1 = list(prediction1[0])\n",
    "                prediction1= SCREWCATEGORIES[prediction1.index(max(prediction1))]\n",
    "                \n",
    "                \n",
    "                if prediction1==\"gewinde\":\n",
    "                    size = (224, 224)\n",
    "                    predimage1 = ImageOps.fit(Image.fromarray(img2), size, Image.ANTIALIAS)\n",
    "\n",
    "                    #turn the image into a numpy array\n",
    "                    predimage1_array = np.asarray(predimage1)\n",
    "\n",
    "                    # Normalize the image\n",
    "                    normalized_predimage1_array = (predimage1_array.astype(np.float32) / 127.0) - 1\n",
    "                    # Load the image into the array\n",
    "                    preddata1[0] = normalized_predimage1_array\n",
    "\n",
    "\n",
    "                    prediction1=screwmodel.predict(preddata1)\n",
    "                    prediction1 = list(prediction1[0])\n",
    "                    prediction1= SCREWCATEGORIES[prediction1.index(max(prediction1))]\n",
    "\n",
    "                partname=compare(prediction1,dimA,dimB)\n",
    "                prediction=prediction1\n",
    "                \n",
    "            \n",
    "            #-------------Washer\n",
    "            \n",
    "            elif(prediction==\"unterlegscheibe\"):\n",
    "                dimension1=0\n",
    "                dimension2=0\n",
    "                edged2 = cv2.Canny(washerimage, mincanny, maxcanny)\n",
    "                edged2 = cv2.dilate(edged2, None, iterations=1)\n",
    "                edged2 = cv2.erode(edged2, None, iterations=1)\n",
    "                cntswasher = cv2.findContours(edged2.copy(), cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
    "                cntswasher = imutils.grab_contours(cntswasher)\n",
    "                \n",
    "                for j in cntswasher:\n",
    "                    if cv2.contourArea(j) < 100:\n",
    "                        continue\n",
    "                    box2 = cv2.minAreaRect(j)\n",
    "                    box2 = cv2.cv.BoxPoints(box) if imutils.is_cv2() else cv2.boxPoints(box2)\n",
    "                    box2 = np.array(box2, dtype=\"int\")\n",
    "                    box2 = perspective.order_points(box2)\n",
    "                    (tl2, tr2, br2, bl2) = box2\n",
    "                    (tltrX2, tltrY2) = midpoint(tl2, tr2)\n",
    "                    (blbrX2, blbrY2) = midpoint(bl2, br2)\n",
    "                    (tlblX2, tlblY2) = midpoint(tl2, bl2)\n",
    "                    (trbrX2, trbrY2) = midpoint(tr2, br2)\n",
    "                    dA2 = dist.euclidean((tltrX2, tltrY2), (blbrX2, blbrY2))\n",
    "                    dB2 = dist.euclidean((tlblX2, tlblY2), (trbrX2, trbrY2))\n",
    "                    dimA2 = dA2 / pixelsPerMetric\n",
    "                    dimB2 = dB2 / pixelsPerMetric\n",
    "                    #print(dimA2)\n",
    "                    #print(dimB2)\n",
    "                    if(((dimA2+dimB2)/2)>dimension1):\n",
    "                        dimension1=((dimA2+dimB2)/2)\n",
    "                    elif(((dimA2+dimB2)/2)>dimension2):\n",
    "                        dimension2=((dimA2+dimB2)/2)\n",
    "                partname=compare(\"unterlegscheibe\",dimension1,dimension2)\n",
    "                        \n",
    "                        \n",
    "            #----------Domenuts\n",
    "            \n",
    "            elif prediction==\"hutmutter\":\n",
    "                prediction=domenutmodel.predict(preddata)\n",
    "                prediction = list(prediction[0])\n",
    "                prediction= DOMENUTCATEGORIES[prediction.index(max(prediction))]\n",
    "                if prediction==\"hutmutter_oben\":\n",
    "                    partname=compare(\"mutter\",dimA,dimB)\n",
    "                else:\n",
    "                    partname=compare(\"dome_side\",dimA,dimB)\n",
    "                    \n",
    "            else:\n",
    "                partname=compare(prediction,dimA,dimB)\n",
    "                \n",
    "\n",
    "            \n",
    "            cv2.putText(orig,partname ,\n",
    "                (int(trbrX + 10), int(trbrY+20)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.55, (0, 0, 0), 2)\n",
    "            \n",
    "            cv2.putText(orig,prediction,\n",
    "                (int(trbrX + 10), int(trbrY+35)), cv2.FONT_HERSHEY_SIMPLEX,0.55, (0, 0, 0), 2)\n",
    "\n",
    "\n",
    "    (h, w) = orig.shape[:2]\n",
    "    cv2.rectangle(orig, (safetyzonex,safetyzoney), (w-safetyzonex,h-safetyzoney), (0, 0, 255) , 2)\n",
    "    cv2.imshow('Capturing Video',orig)\n",
    "    cv2.imshow('contour',edged)                        \n",
    "\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        videoCaptureObject.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        active=False\n",
    "    \n",
    "print(\"exit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.uint8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predimage[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "washer\n",
      "[0.98790723, 0.008936687, 9.253132e-05, 0.003063515]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "CATEGORIES = [\"washer\",\"nut\",\"zylinder\",\"hex\"]\n",
    "\n",
    "# Load the model\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1.\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "# Replace this with the path to your image\n",
    "image = Image.open('test20.jpg')\n",
    "\n",
    "#resize the image to a 224x224 with the same strategy as in TM2:\n",
    "#resizing the image to be at least 224x224 and then cropping from the center\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "\n",
    "#turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "\n",
    "# display the resized image\n",
    "#image.show()\n",
    "\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array\n",
    "\n",
    "# run the inference\n",
    "prediction = model.predict(data)\n",
    "prediction = list(prediction[0])\n",
    "print(CATEGORIES[prediction.index(max(prediction))])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize all images in one folder\n",
    "\n",
    "import PIL\n",
    "import os\n",
    "import os.path\n",
    "from PIL import Image\n",
    "\n",
    "f = r\"C:/Users/maxim/Documents/Python/data/Traingoogle/senkkopf\"\n",
    "for file in os.listdir(f):\n",
    "    f_img = f+\"/\"+file\n",
    "    img = Image.open(f_img)\n",
    "    img = img.resize((256,256))\n",
    "    img.save(f_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getscrewhead(screwimg):\n",
    "    \n",
    "    img = Image.fromarray(screwimg)\n",
    "    \n",
    "    \n",
    "  \n",
    "    # Size of the image in pixels (size of orginal image) \n",
    "    # (This is not mandatory) \n",
    "    width, height = img.size \n",
    "\n",
    "\n",
    "    # Cropped image of above dimension \n",
    "    # (It will not change orginal image) \n",
    "    image1 = img.crop((0, 0, width, width*0.6))\n",
    "    image2 = img.crop((0, height-(width*0.6), width, height))\n",
    "    return(image1,image2)\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "# Opens a image in RGB mode \n",
    "im = cv2.imread(\"test.jpg\") \n",
    "  \n",
    "im1,im2=getscrewhead(im)\n",
    "im1.show() \n",
    "im2.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
